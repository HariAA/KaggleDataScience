{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HS_Osmosis_Quora_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HariAA/KaggleDataScience/blob/master/HS_Osmosis_Quora_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3v8nGzMRJ3nA",
        "colab_type": "code",
        "outputId": "4fa0bbd6-889f-4913-f7c8-35d49a388063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 22.0MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 3.8MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 4.5MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 5.8MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 6.4MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 5.0MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 5.0MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 6.9MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 6.9MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 12.5MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 12.6MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 12.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 12.4MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 12.5MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 12.5MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 45.1MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 15.0MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 15.0MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 15.2MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 15.2MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 15.2MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 14.4MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 14.9MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 14.9MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 14.8MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 15.2MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 50.6MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 50.9MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 52.1MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 46.9MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 46.8MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 56.2MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 56.0MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 57.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 18.8MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 18.5MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 18.6MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 18.7MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 18.7MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 18.8MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 17.4MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 17.3MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 17.3MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 17.2MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 45.1MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 43.1MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 42.9MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 42.9MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 42.2MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 46.3MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 57.8MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 59.2MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 59.6MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 58.7MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 57.5MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 63.2MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 63.7MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 63.6MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 24.2MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 23.5MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 20.8MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 20.7MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 20.7MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 20.6MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 20.4MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 20.3MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 20.2MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 20.0MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 41.0MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 42.5MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 55.6MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 56.5MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 55.1MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 57.7MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 59.0MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 59.5MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 60.5MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 61.1MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 62.8MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 53.6MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 53.3MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 54.4MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 55.8MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 56.2MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 56.6MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 56.4MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 56.8MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 56.7MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 55.7MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 67.1MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 67.8MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 66.2MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cYzJ2E2sYE-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from keras.callbacks import Callback\n",
        "import re\n",
        "import gensim\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU ,Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Layer\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import logging\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWEkQounbGco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DdWb2jjmbKSa",
        "colab_type": "code",
        "outputId": "f8d2ee30-f56f-4d28-ba2d-b878dbedfe5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "listed = drive.ListFile({'q': \"title contains '.bin'\"}).GetList()\n",
        "print(len(listed))\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "title GoogleNews-vectors-negative300.bin, id 1AZi1XiJMos56bN-fq9N9ASkOdMu1CPqT\n",
            "title GoogleNews-vectors-negative300.bin.gz, id 0B7XkCwpI5KDYNlNUTTlSS21pQmM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OAX3KewncxZD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_file_id = '1fmaURsOvi4yMghZeDwEDqiXFBGet2VPy'\n",
        "test_file_id = '1ibmBLfU_P9Hkg0Dh2HUTNS6y2mNKD6E3'\n",
        "glove_file_id='1vF1l9mUNKc8fNlLTUy2AP4i5qvOeqkJW'\n",
        "google_word2_vec_id='1AZi1XiJMos56bN-fq9N9ASkOdMu1CPqT'\n",
        "downloaded = drive.CreateFile({'id': train_file_id})\n",
        "downloaded.GetContentFile('train.csv')  \n",
        "downloaded = drive.CreateFile({'id': test_file_id})\n",
        "downloaded.GetContentFile('test.csv')  \n",
        "downloaded = drive.CreateFile({'id': glove_file_id})\n",
        "downloaded.GetContentFile('glove.txt')  \n",
        "downloaded = drive.CreateFile({'id': google_word2_vec_id})\n",
        "downloaded.GetContentFile('w2v.bin')  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hb_SQ7cYPNX",
        "colab_type": "code",
        "outputId": "fef8e04c-d84d-4895-9d6f-78d4719c6f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_data=pd.read_csv('train.csv')\n",
        "test_data=pd.read_csv('test.csv')\n",
        "train_data.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00004f9a462a357c33be</td>\n",
              "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00005059a06ee19e11ad</td>\n",
              "      <td>Why does Quora automatically ban conservative ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0000559f875832745e2e</td>\n",
              "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00005bd3426b2d0c8305</td>\n",
              "      <td>Is there such a thing as dressing moderately, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00006e6928c5df60eacb</td>\n",
              "      <td>Is it just me or have you ever been in this ph...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text  \\\n",
              "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
              "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
              "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
              "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
              "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
              "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
              "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
              "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
              "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
              "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
              "\n",
              "   target  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  \n",
              "5       0  \n",
              "6       0  \n",
              "7       0  \n",
              "8       0  \n",
              "9       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "it7Lh6osdgqI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_data(questions):\n",
        "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\’)|(\\‘)|(\\”)|(\\“)|(\\…)|(\\–)|(\\→)|(\\−)|(\\∞)\")\n",
        "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "    questions = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in questions]\n",
        "    questions = [REPLACE_WITH_SPACE.sub(\" \", line) for line in questions]\n",
        "    questions = [re.sub(r'\\d+', '', line) for line in questions]\n",
        "    \n",
        "    return questions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKspuLYXauq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data['question_text'] = clean_data(train_data['question_text'])\n",
        "test_data['question_text'] = clean_data(test_data['question_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3fa_QFlvtXOL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x_train, x_cv, y_train, y_cv=train_test_split(train_data['question_text'],train_data['target'],test_size=0.2)\n",
        "#x_train=train_data[train_data.target==[1]]['question_text']\n",
        "x_train=train_data['question_text']\n",
        "y_train=train_data['target']\n",
        "x_test=test_data['question_text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKJook3btZsN",
        "colab_type": "code",
        "outputId": "d9b412f5-68ca-4594-bf90-0507465b141a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "i=0\n",
        "print(\"Parsing sentences from training set\")\n",
        "for question in x_train:\n",
        "    if i % 100000 ==0: print(i)\n",
        "    #print(gensim.utils.simple_preprocess(question))\n",
        "    \n",
        "    \n",
        "    sentences.append(list(gensim.utils.simple_preprocess(question,min_len=1, max_len=50 )))\n",
        "    #print(sentences[i])\n",
        "    \n",
        "    i+=1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing sentences from training set\n",
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_vcylnitcUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jDWshretfMv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_features=300\n",
        "min_word_cnt=1\n",
        "window=10\n",
        "num_workers=4\n",
        "#word_model=Word2Vec(sentences,workers=num_workers,size=num_features,min_count=min_word_cnt,window=window)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dt_xzfnFtgx7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#word_vectors = KeyedVectors.load_word2vec_format('w2v.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n149ZrdtKv32",
        "colab_type": "code",
        "outputId": "5ea01042-094f-4032-f5a5-35c5a94bb8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_train.append(x_test).shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1306122,)\n",
            "(1362492,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BeboU6YsK0ON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e2925ec3-b682-4895-c626-17d29f60bd5c"
      },
      "cell_type": "code",
      "source": [
        "tott=x_train.append(x_test)\n",
        "tok = Tokenizer(lower=True)\n",
        "tok.fit_on_texts(tott)\n",
        "sequences_train = tok.texts_to_sequences(x_train)\n",
        "sequences_test = tok.texts_to_sequences(x_test)\n",
        "word_index=tok.word_index\n",
        "num_words=len(word_index)+1\n",
        "print(num_words)\n",
        "pad_sequence_train=pad_sequences(sequences_train, maxlen=133)\n",
        "pad_sequence_test=pad_sequences(sequences_test,maxlen=133)\n",
        "print(pad_sequence_train.shape)\n",
        "print(pad_sequence_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198558\n",
            "(1306122, 133)\n",
            "(56370, 133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kP_cRxO8K3MW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae255f79-a1eb-4baa-bbd8-35854bfc0d84"
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.txt',encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0] ## The first entry is the word\n",
        "    coefs = np.asarray(values[1:], dtype='float32') ## These are the vecotrs representing the embedding for the word\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('GloVe data loaded')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GloVe data loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uPxCMRRqK5Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f158a158-83cb-46e4-f842-ae4b8f4d23a5"
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix=np.zeros((num_words,300))\n",
        "not_found=0\n",
        "word_found=0\n",
        "wc_found=0\n",
        "not_found_words=[]\n",
        "for word,i in word_index.items():\n",
        "    try:\n",
        "        #embedding_vector=word_vectors[word]\n",
        "        embedding_vector=embeddings_index.get(word) \n",
        "        embedding_matrix[i]=embedding_vector\n",
        "        word_found+=1\n",
        "        if embedding_vector is None:\n",
        "            #continue\n",
        "            #embedding_matrix[i]=word_vectors[word]\n",
        "            embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),300)\n",
        "            #embedding_matrix[i][0]=25\n",
        "            wc_found+=1\n",
        "            #not_found_words.append((word,i))\n",
        "    except KeyError:\n",
        "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),300)\n",
        "        not_found_words.append((word,i))\n",
        "        #print(word)\n",
        "        #print(i)\n",
        "        #if i > 1000: break;\n",
        "        not_found+=1\n",
        "       # print('%s not found' %(word))\n",
        "print('%s words found and %s words not found' %(word_found,wc_found))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198557 words found and 79233 words not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ijYIv89VK7S0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_layer=Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                            output_dim=embedding_matrix.shape[1], \n",
        "                            input_length=133,\n",
        "                            weights=[embedding_matrix], \n",
        "                            trainable=False, \n",
        "                            name='embedding_layer')\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(GRU(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "#model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h1WRB7Jp0_HX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "bb4f600f-62e6-4df7-877d-0cf6969b928c"
      },
      "cell_type": "code",
      "source": [
        "del embeddings_index"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ad1c4339427f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings_index' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4TqlVjvsK-pX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c3549d1c-5283-4ba0-f9fd-d0f07f060e48"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])  # Compile the model\n",
        "print(model.summary())  # Summarize the model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_layer (Embedding)  (None, 133, 300)          59567400  \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 128)               164736    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 59,732,265\n",
            "Trainable params: 164,865\n",
            "Non-trainable params: 59,567,400\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "010bItNk1Q9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Metrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.v_f1 = []\n",
        "        self.v_recall = []\n",
        "        self.v_precision = []\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        v_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
        "        v_targ = self.validation_data[1]\n",
        "        _v_f1 = f1_score(v_targ, v_predict)\n",
        "        _v_recall = recall_score(v_targ, v_predict)\n",
        "        _v_precision = precision_score(v_targ, v_predict)\n",
        "        self.v_f1.append(_v_f1)\n",
        "        self.v_recall.append(_v_recall)\n",
        "        self.v_precision.append(_v_precision)\n",
        "        print (' — v_f1: %f — v_precision: %f — v_recall %f' %(_v_f1, _v_precision, _v_recall))\n",
        "        return\n",
        " \n",
        "metrics = Metrics()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWNCsfkLLBAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a0c13cd0-6a5a-42c3-c24c-a272fc742d86"
      },
      "cell_type": "code",
      "source": [
        "pad_sequence_t, pad_sequence_cv, y_t, y_cv=train_test_split(pad_sequence_train,y_train,test_size=0.2)\n",
        "print(pad_sequence_t.shape)\n",
        "print(pad_sequence_cv.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1044897, 133)\n",
            "(261225, 133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0P8Dj2dsLDG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7a292783-4bd4-4d45-e108-49d6cd6619d4"
      },
      "cell_type": "code",
      "source": [
        "model.fit(pad_sequence_t, y_t, batch_size=128, epochs=5, verbose=1, validation_data=(pad_sequence_cv,y_cv), callbacks=[metrics])  # Fit the model\n",
        "#loss, accuracy = model.evaluate(pad_sequence_t, labels, verbose=0)  # Evaluate the model\n",
        "#print('Accuracy: %0.3f' % accuracy)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f5ddbacd7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_sequence_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_sequence_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#loss, accuracy = model.evaluate(pad_sequence_t, labels, verbose=0)  # Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print('Accuracy: %0.3f' % accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GnleXTTDLFKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#word_index['which']\n",
        "#word_vectors['which']\n",
        "df_list=pd.DataFrame({'word':not_found_words, 'val':1})\n",
        "#df_list['word']=df_list['word'].strip()\n",
        "print(df_list.groupby(df_list['word']).sum().sort_values(['word'],ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRX-9lXcLIiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred=model.predict_classes(pad_sequence_test)\n",
        "submission=pd.DataFrame({'qid':test_data['qid'],'prediction':y_pred.ravel()},columns=['qid','prediction'])\n",
        "submission.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}